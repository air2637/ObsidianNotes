### Application Communication

- Synchronous - application directly to application, but **problematic if the traffic spikes**
- Asynchronous (Event) - application -> queue -> application, good for **decoupling applications**, 
	- SQS - queue model
	- SNS - pub & sub model
	- Kinesis - realtime streaming model

## SQS

- Standard Queue
	- unlimited throughput
	- unlimited of messages in the queue
	- retention - 0 - 14 days, default to 4 days
	- **limitation on message size of 256kb**
	- could be duplicating a same message (sent > 1 times)
	- consumer side:
		- could be ec2, on-premise server, aws lambda etc
		- it needs to consume **and delete** the message (with DeleteMessage API)
		- up to 10 messages being polled at a time
		- **if the message is not processed fast enough, it will be sent to other consumer**
- First in - First out Queue, **ordering guaranteed**
	- **Limited throughput**
	- Exactly once send (It auto removes the duplicates) - configurable
 
### Typical SQS infra design

**Auto scaling the consumer e.g. EC2 amount based on the size of messages pending in the SQS - ==CloudWatch Metric - Queue Length==**
1. The metric triggers CloudWatch Alarm
2. ASG receive the alarm and auto scale consumer amount

Simple design:
1. CloudWatch metric - Queue length: to check how many pending messages in the queue and generate CloudWatch Alarm
2. SQS Queue --(poll message) --> EC2 instance (Managed by Auto scaling Group) --(monitored and scaled by) --> Cloudwatch Alarm

Decoupled Application Tiers:
	e.g. **video processing**
		1. request sent to front-end web app (ASG)
		2. message is stored in sqs
		3. back-end processing app(ASG) poll the request and process
		4. store the result in S3
	  e.g. ==SQS as a buffer space for DB transactions== - High throughput DB writes may get lost if beyond what DB server can handle, so similar to the video processing design, we use SQS as the buffer for the write transactions:
		  1. Web app send transactions to SQS **Enqueue messages**?
		  2. Another ASG server group to **Dequeue messages** and writes to DB, so the server has logic to **ONLY delete the message if the transaction has been successfully written to DB**


### SQS Security

- Encryption:
	- In-flight encryption with HTTPS
	- at-rest encryption with KMS key
	- client side encryption can be managed by client side
 - Access Control - IAM polices
 - SQS Access Policy (Similar to S3 bucket policy [[12 Amazon S3 Introduction (47mins)#S3 Security]])
	 - For cross-account access to SQS
	 - For allowing other services(e.g. SNS, S3 etc) to write to an SQS

### SQS configurations

- ==Message Visibility Timeout== - during the time window, SQS will not send the message to other consumers:
	- You - the current consumer of the message has to process and **delete** it, otherwise, it will be picked up by others
	- default to 30 seconds
	- API - **ChangeMessageVisibility** if you can't finish the processing within the timeout window, and let SQS **NOT** to send the message to others
- ==Long polling==
	- As a consumer - you are fine with keeping the session to SQS open for longer time, and waiting for any new messages
	- It helps reduce the **Number of API calls**, and **latency in consuming the message** -> so **Long polling always preferred over short polling**
	- How to enable
		- at queue level
		- at api level using **WaitTimeSeconds**
- Group ID
	- an attribute that can be used to identify business logically linked messages (like **partition key of Kinesis Data Stream**)

## SNS

- In contrast to SQS, that SNS sends one message to **many receivers**
- what can be the **subscribers**?
	- Emails, SMS
	- HTTP(S) endpoints
	- SQS
	- Lambda
	- Kinesis Data Firehose
- What AWS service can produce SNS topic?
	- CloudWatch Alarms
	- AWS budgets
	- Lambda
	- ASG
	- S3 notification
	- etc 
 - ==data is not persisted (if not delivered, it is lost)==

### Security - similar to [[#SQS Security]]

### SNS + SQS for Fan-out pattern

==You want send one message to multiple queues== - with concerns:
- robust to new queue (if I want to add)
- If broadcast via an EC2, the server could be down
- Cross region SQS queues
So you need ensure the **access policy** of SQS is granted for the SNS

### SNS with message filtering

- the filtering rule has to be specified in the **policy json** to the ==**subscription**==, so the SNS subscriber will only receive the desired message type
	e.g. Buying service
	1. Front system send buying message (e.g. New transaction, state: placed) to SNS topic
	2. One SQS queue with subscription policy saying - to get message of state placed
	3. One SQS queue with subscription policy saying - to get message of state - delivered

## Kinesis

- for **live streaming** data collect, process, and analyze
- stream data (large throughput, realtime), e.g. application logs
- Components:
	- Kinesis Data Streams - capture, process and store (like SQS/SNS, that it is a **agent like service that converts data into stream**)
	- Kinesis Data Firehose - load data streams into AWS data store (for **loading streams into S3, Splunk etc**)
	- Kinesis Data Analytics - analyze stream data with SQL / Apache Flink
	- Kinesis Video Streams - capture, process and store video streams

### Kinesis Data Streams

- data is split into **shards**
- data flow:
	- Producer produces the stream data in **Record** format:
		- Producer can be applications, Kinesis Agent, etc
		- Record contains **Partition key** which tells which **Shard** the data should be stored, and data itself in **Data Blob**
	- Kinesis Data Streams:
		- contains **Shard** - the residence for data
	- Consumers poll **Record** and process:
		- Record contains - **Partition Key**, **Sequence no.** - the location of data in the **Shard**,and of course the data in **Data Blob**
		- The consumers can be Application (with SDK), Lambda, **Kinesis Data Firehose, and Kinesis Data Analytics**
- other characteristics:
	- Retention between 1 to 365 days - so replay is possible
	- **Once data inserted, it can NOT be deleted**
	- Data stream capacity:
		- Provision Mode - you tell the capacity in advance, e.g.
			- Each shard get 1 MB/s  as input
			- Each shard ouput data at 2 MB/s
		- On-demand Mode - you set nothing but let AWS to decide based on past 30 days throughput
	- **data ordered at Shard level**
 
### Kinesis Data Stream Security

- again, similar to what SQS does [[#SQS Security]]
- how to access:
	- EC2 sits int a VPC
	- connects to Kinesis Data Stream via an **VPC Endpoint** [Damn, so abstract, but do read passage with diagram too](https://docs.aws.amazon.com/whitepapers/latest/aws-privatelink/what-are-vpc-endpoints.html)  , for my own understanding see ref [^seeRef1]

[^seeRef1]:
- Seems like VPC endpoint contains 2 kinds - **interface endpoint** and **gateway endpoint**, and both are **virtual devices**:
	- Interface endpoint: enable the connectivity to **AWS services** via **AWS privateLink**
	- Gateway endpoint: **a prefix-list resides in an AWS VPC route table** (as good as saying nothing)

### Kinesis Data Firehose

- key words:
	- **Near realtime (60 seconds delay?)** - so bigger buffer size, bigger delay time, but less re-connection to the Store
	- You can transform data with **Lambda**

### The difference between Data Streams and Data Firehose

Data stream is the agent converting data into streams, while the Firehose is for loading streams into store (e.g. S3, Splunk), details seen [here](https://www.whizlabs.com/blog/aws-kinesis-data-streams-vs-aws-kinesis-data-firehose/)


## Kinesis vs. SQS with use case

We have 100 trucks that sends their realtime GPS data to a command centre, so we implement the solution with Kinesis , SQS respectively:

- Kinesis
	- We assign each truck the truck id (e.g. 1 to 100), and we hash the truck id (e.g. 100%5=?), since we decided to use 5 **shards**
	- so the GPS data is sent to Kinesis Data Stream Shard 1 for trucks if truck id in (1, 6, 11 etc), and data added for each truck in a Shard is in-ordered
	- We have to have 5 consumers, as each shard gets one. So **maximum 5 parallel processing**
- SQS
	- We have one SQS FIFO queue for receiving the data from all trucks, and we have 100 group id, each id corresponds to the truck id
	- We have 100 consumers and each hook to one truck id
	- so it is 100 parallel processing (depends on the scale of the consumer)