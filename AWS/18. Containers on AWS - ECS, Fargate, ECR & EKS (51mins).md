## Docker containers Management on AWS

- ECS - Elastic Container Service, Amazon's own **container platform**
- EKS - Elastic Kubernetes Service, managed Kubernetes
- Fargate - AWS's own **serverless container platform**, works with both ECS and EKS
- ECR - Store container images


## ECS Launch Types

- EC2 launch type
	- you need a ec2 as the server, and you manage the instance
	- on the instance, ECS agent is installed and running - take cares the start/stop of containers
- Fargate launch type
	- it has a server to run your container, but is transparent to you. Meaning you don't need to manage the underlying infra, however, you need to **tell the desired CPU, RAM**
	- A container is a **task, created by task definitions**
	- Instead, for scaling, you just specify the **Task**
- Both EC2 launch type and Fargate can **co-exist in a cluster**

## ECS - IAM roles

- EC2 instance role - a generic role created and used by the EC2 instance (so it is EC2 launch type only)
	- Basic permission needs to be granted: 
		- make api call to ECS service (?? what are they??) , 
		- pull docker image from ECR
		- push logs to CloudWatch
		- get sensitive date from Secret Manager or SSM Parameter Store
  
- ==ECS Task role== - the role used by a **Task Definition**, e.g. task A needs to access S3, while task B needs to access RDS


## ECS - Load Balancing

- Application Load Balancer - **recommended**
	- applicable to both EC2 Launch Type, and Fargate Launch type
	- Traffic not only simply routed to the instance level, but the **Task level**
- Network Load Balancer -
	- Similar support as per ALB
	- **You only use this if high throughput is required**

## ECS - Data Volumes

- Use EFS - network file system
	- mounted at **Task level**
	- So support multi AZ, meaning your tasks can run multi AZs
	- applicable for both EC2 Launch Type and Fargate Launch Type

## Hands-on

- Create a ECS cluster, Fargate is enabled by default, but you can also add EC2 launch type
- You specify the minimum and maximum instance for the cluster
- You want an ALB sitting in front of the cluster, hence you do:
	- Create Security Group for both ALB and ECS task respectively, where the **SG for ALB should allow Internet access from anywhere**, and the **SG for ECS task is assigned with the SG of ALB**
- Then you create a ECS task definition, by specifying:
	- image info e.g **image URI**, port, etc
	- **APP environment** - either AWS Fargate, or EC2 instance
	- **Task role** if needed
- Start the task:
	- You specify the ALB, with **target group** set to the SG of the one created for ECS task
	- Task size - cpu, ram
	- Long running service: for web app
	- Batch job task: for a run and complete job
 
## ECS - Auto scaling (EC2 launch type, as Fargate does not need)

- automatically increase / decrease the number of **ECS Tasks** (not the instance!)
- auto scaling with **ASG**
	- Metric is monitored - Average CPU utilization, Average Memory utilization, ALB Request count per target
	- CloudWatch Alarm is created with exceeding the threshold
	- Application Auto Scaling will increase/decrease the ECS tasks
- auto scaling with ==ECS Cluster Capacity Provider==
	- scale the ECS tasks
	- work together with ASG for scale the ec2 instances when cpu, memory threshold met

## EKS

What is Kubernetes?
- an alternative to ECS, similar goal but different API
- for automatic deployment, scaling, and managing of containerized applications
- unlike ECS only for AWS, kubernetes is cloud-agnostic

So use EKS if:
- you are already using Kubernetes on premise
- want to migrate your stack to AWS
- or you just prefer Kubernetes over ECS

Understand EKS as an analogy to ECS:
- **Work node** -> like in EC2 instance launch type, the ec2 instance for ECS
- **EKS pod** -> like the **Task for ECS**

EKS - Data volumes:
- EBS
- EFS (the only type that supports Fargate)
- FSx for Lustre
- FSx for NetApp ONTAP

## AWS App Runner

- A instant service for deploying web app, API at scale, you dont need to know the underlying infra
- start with source code / container
	- source code from github
	- container from a registry
- behind scene, it manages:
	- auto scaling
	- load balancer
	- vpc access
	- db
	- message queue 
	- etc
- Use case:
	- web app
	- api
	- microservices
	- rapid production deployment
	
