### AWS Snow Family

- ordered from small (both in physical size and the storage volume) to big:
	- Snowcone - up to 24 TB, available to both online and offline
	- Snowball Edge - up to Petabyte
	- Snowmobile - up to Exabyte
- how data is transferred?
	1. Request Snowball devices from AWS console
	2. Install the **snowball client** or **AWS OpsHub**(GUI do what aws cli does) on client server
	3. Connect the snowball to client server and copy data
	4. Ship back the device
	5. Load data into S3
	6. Snowball is completely wiped
- **Edge computing** at **Edge locations** (places hard to get internet access):
	- Use Snowcone/ SnowEdge
		- it has **CPU, Memory**
		- can run EC2 instances, lambda embedded
	- Process data, machine learning
	- eventually if needed, can be ship back to AWS
 - Transfer data from **Snowball** to **Glacier**:
	 - no direct way
	 - Snowball -> S3 -> S3 lifecycle policy triggers [[12 Amazon S3 Introduction (47mins)#S3 Storage Class]] -> Glacier

### FSx (file server)

- FSx for windows
	- in Windows file system, supports SMB protocol and Windows NTFS
	- Integrated with **Active Directory** , **Microsoft Distributed File System (DFS)**
	- can be mounted onto **Linux EC2 instance** too
- FSx for lustre (Linux Cluster) 
	- **Parallel distributed file system** , for **large scale computing**
	- **Seamless integration with S3** - upload / download s3 files as if it is within file system

#### FSx Deployment options

- Typical architecture
	- It supports Compute Servers from **different AZs** though the FSx stays in one of the AZ, with ENI as the interface communicating with Computer Server (e.g. EC2) from both current AZ and other AZs
- Scratch File System
	- Single FSx for the support
	- Short term processing, for cost
- Persistent File system
	- Two FSx for the support, and data is replicated between the two
	- Supports failover
	- Long term processing, for failover

#### FSx for NetApp ONTAP

- um.. File system compatible for **NFS, SMB, iSCSI** protocol
- Storage shrinks/ grows automatically
- **Point in time instantaneous cloning** - e.g. for testing new workload 

#### FSx for OpenZFS

- Only support NFS protocol
- Excellent on IOPS

### Hybrid Cloud support

- part of the infra on cloud and remaining on premises
- S3 is a proprietary storage technology (unless EFS / NFS), so how to expose the **S3 data on premises**? - **Storage Gateway**
	- Bridge between on premises data and cloud data
	- use cases - DR, Tiered storage, etc
	- Types:
		- S3 File Gateway
			- supports **S3 standard, S3 standard IA, S3 One-zone IA, S3 Intelligent Tiering**
			- On premise server connects to the Gateway via **NFS / SMB** -> Gateway connects to S3 via **HTTPS**
			- To access files stored on S3:
				- **IAM role for each S3 Gateway**
				- SMB protocol integrated with Active Directory (AD) for user authentication
		- FSx Gateway
			- Benefits over using FSx as file system is **Local cache for frequently access data**
		- Volume Gateway
			- **Backed by EBS that back up and restore your on premise volumes**
			- types:
				- Cached Volume
				- Stored Volume
			- Application server -> Volume Gateway -> S3 bucket -> EBS snapshots
		- Tape Gateway
			- backup data from Tape (the old school tape)

### Transfer Family

- FTP interface into S3 or EFS
- kinds:
	- AWS Transfer for FTP
	- AWS Transfer for FTPS (FTP over SSL)
	- AWS Transfer for SFTP (SFTP)
 - ==Typical setup==
	 - User send file through FTP to a address registered on **Route 53**
	 - **Route 53** routing to the one of the FTP interface
	 - With the aid of IAM role (assumeRole) it uploads/downloads to **S3 or Amazon EFS**

### AWS DataSync

- Move large amount of data to/from (**two way**):
	- On-premise <> AWS cloud
	- AWS <> AWS, e.g. among AWS S3, EFS, FSx
	- ==It is not **continuous** but **scheduled cron job**
- ==Metadata is preserved, e.g. File permission etc==
- Snowcone with built-in DataSync if client has not network access

## Summary of Storage comparison

- S3 - object storage
- S3 glacier - object archival
- EBS - Network storage for **One EC2 instance at a time**, multi-attach available for IO1 , IO2 only [[7. EC2 instance storage#Multi-attach]]
- Instance Storage - Physical storage connected to EC2 (high IOPS)
- EFS - **Network File System** for linux system ?? [[7. EC2 instance storage#Finally, EBS vs EFS]]
- FSx for windows - Network file system for windows system
- FSx for Lustre - High performance Linux file system
- FSx for NetApp Ontap - **High OS compatibility**
- FSx for OpenZFS

- Bridging purpose
	- Storage Gateway
	- Transfer Family
	- DataSync
	- Snowcon/Snowball/Snowmobile if not network access
