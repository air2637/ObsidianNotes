# What is the flow?
1. Write app/ small independent micro-services
2. Package the app/micro-services into container
3. Wrap container in a ==Kubernetes Pod==
4. Deploy Pods to the cluster
==Kubernetes manage apps declaratively.==

# What consists of a cluster?
1. Control Plane
2. Worker Nodes
3. Kubernetes DNS
---

## Control plane

- Expose the API
- Has a scheduler for assign work
- Record the state of cluster and app in a persistent store
- Provide clever features:
	- scheduling
	- auto-scaling
	- rollouts
- Configured for High Availability(HA) and should be spread across several Availability Zones 

### Components of Control plane

#### The API server:
> All communication between all components must go through the API server.

#### The Cluster store:
> Store the entire configuration, state of the cluster.

- Based on a distributed database called *etcd* - prefers consistency over availability
- Should be run on 3-5 replicas for HA
- Kubernetes default the cluster store on every control plane

#### The Controller Manager and Controllers
> Controller Manager is the controller of the controllers, means it spawns all the core controllers and monitors them.

> Controllers: ensure the ==observed state== matches the ==desired state==.

Deployment controller vs. StatefulSet controller vs. ReplicateSet controller 

#### The Scheduler
> It watches API server for new tasks and assigns them to *appropriate* worker nodes

#### The Cloud Controller Manager
> Support for cloud platforms e.g. AWS, features integrating with cloud services, e.g. instances, load-balancers etc.

---

## Worker Nodes

- Run user apps
	1. Watch API server for new tasks
	2. Execute the task
	3. Report back to API server of Control Plane

### Components of Worker Nodes

#### 1.Kubelet
> It is Kubernetes agent, register the node's CPU, memory, storage into the cluster pool


#### 2.Container runtime
> Perform container related operations, e.g. pulling image, starting/stopping container

#### 3.Kube-proxy
> Support local cluster networking

### Pods vs. Container
In simple use case, that a container is run in a Pod. However, advance cases that run multiple container in a Pod.[^1] Pod is a ring-fenced environment to run container(s).

The ring-fenced environment, specifies:
- Network stack
- Volumes
- IPC namespaces
- Shared memory
- etc

[^1] Multiple containers in a Pod happens between a main container + other supportive container(s) cases

#### Pods as the unit of scaling
> Minimum unit of scheduling in K8s

If you need to scale an app, you add/remove the pod. You **don't** scale by adding/removing more containers to the pod.

#### Pods lifecycle
> K8s always start a new Pod when the old one dies

Don't design the apps tightly coupled to **a particular instance of Pod**.

#### Service Objects
> K8s API object that provides reliable name and IP, act as the load-balancer for a set of Pods behind it.

e.g. 2 Renderers sit behind the Renderer service

![[Screenshot 2022-11-12 at 3.07.13 PM.png]]


## DNS Service
Ensure static IPs assigned to each pod

---

# Packaging apps for K8s

Steps:
1. Package app as a container
2. Wrap it in a Pod
3. Deployed via declarative manifest file
4. Load the manifest file into the API server

## What does K8s do upon receiving the manifest file?

1. Find the Deployments controller
2. Record the config into Cluster Store
3. Worker Nodes: pull image, start container, attach to networks, start app
4. Controller consistently monitor the state of the cluster

The declarative model described at above, in contrast to imperative model[^1]

[^1] Write long script to tell how to build and monitor states.


